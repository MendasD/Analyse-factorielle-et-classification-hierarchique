col.var = "red",
col.ind = "blue",
repel = TRUE) +
theme_minimal()
data_kmeans$classe_indice <- factor(data_kmeans$classe_indice, levels = c(1,2,3,4), labels = c("Pays développés et avancés","Pays à économie agricole et faible développement","Pays en développement et à économie tertiaire","Pays émergents et en transition économique"))
# Indice moyen dans chaque groupe
indices_moyens <- data_kmeans %>%group_by(classe_indice) %>%summarize(across(indice, mean, na.rm = TRUE))
indices_moyens
# Distribution des indices dans chaque classe
ggplot(data = data_kmeans, aes(x=classe_indice, y=indice)) +
geom_line(color = "red") +
geom_point(color = "blue", size = 2) +
labs(title = "Distribution des indices normalisés",
x = "classe indice",
y = "Indice") +
theme_minimal() + theme(axis.text.x = element_text(angle = 30, hjust = 1))
# Autres visualisations
# Préparation des données
new_df <- data.frame(
Indice = data_kmeans$indice,
Classe = factor(data_kmeans$classe_indice)
) %>%
arrange(Indice)
# Calcul des moyennes par classe
class_means <- new_df %>%
group_by(Classe) %>%
summarise(mean_val = mean(Indice))
# Création du graphique
ggplot(new_df, aes(x = Indice, fill = Classe)) +
# Histogramme semi-transparent
geom_histogram(aes(y = after_stat(density)),
alpha = 0.5,
position = "identity",
bins = 30) +
# Courbe de densité
geom_density(aes(color = Classe),
alpha = 0,
linewidth = 1) +
# Points sur l'axe x pour montrer la distribution
geom_rug(aes(color = Classe),
alpha = 0.6,
linewidth = 0.5) +
# Lignes verticales pour les moyennes
geom_vline(data = class_means,
aes(xintercept = mean_val, color = Classe),
linetype = "dashed",
linewidth = 0.8) +
# Personnalisation du thème
theme_minimal() +
theme(
legend.position = "top",
panel.grid.minor = element_blank(),
plot.title = element_text(face = "bold"),
plot.subtitle = element_text(color = "grey40")
) +
# Labels
labs(
title = "Distribution des classes par densité",
subtitle = "Chevauchement de l'indice entre classes",
x = "Valeur de l'indice",
y = "Densité",
fill = "Classe",
color = "Classe"
) +
# Échelle de couleurs personnalisée
scale_fill_brewer(palette = "Set2") +
scale_color_brewer(palette = "Set2") +
# Facettes par classe
facet_wrap(~Classe, nrow = 3, scales = "free_y") +
# Ajustement des marges
theme(
strip.background = element_rect(fill = "grey95"),
strip.text = element_text(color = "black", face = "bold")
)
intervalle_indice <- data_kmeans %>%
group_by(classe_indice) %>%
summarize(min_indice = min(indice, na.rm = TRUE),
max_indice = max(indice, na.rm = TRUE))
intervalle_indice
# Copie du dataframe initial, standardisé
data_AFD <- as.data.frame(scale(df))
# Ajout de la colonne classe_indice
data_AFD$classe_indice <- as.factor(data_kmeans$classe_indice)
data_AFD <- rename(data_AFD,
Croi_PIB_hab = "Croi PIB/hab",
Ctr_agri_PIB = "Ctr_agri_PIB(%)",
Poids_Exp_sur_PIB = "Poids_Exp_sur_PIB(%)",
Ctr_Tertiaire_PIB = "Ctr_Tertiaire_PIB(%)",
Ctrind_PIB = "Ctrind_PIB(%)")
head(data_AFD)
# Choix de l'échantilllon test
set.seed(0)
samples <- sample(2, nrow(data_AFD),
replace = TRUE,
prob = c(0.8, 0.2))
training <- data_AFD[samples==1,]
testing <- data_AFD[samples==2,]
# L'analyse discriminante
data_lda <- lda(classe_indice~., training)
data_lda
# Probabilités à priori du groupe
data_lda[["prior"]]
# Moyenne des groupes
data_lda[["means"]]
# Coefficients des discriminants linéaires
data_lda[["scaling"]]
colnames(training)
# Récupérer les clusters de la CAH
cluster_cah <- data_cluster$clust
# Récupérer les classes d'indice
classes_indice <- data_AFD$classe_indice
# Réorganiser les niveaux de manière cohérente
levels_order <- c("Pays à économie agricole et faible développement", "Pays en développement et à économie tertiaire", "Pays émergents et en transition économique", "Pays développés et avancés")
# Ajuster les niveaux pour cluster_cah et classes_indice
cluster_cah <- factor(cluster_cah, levels = levels_order)
classes_indice <- factor(classes_indice, levels = levels_order)
# Croisement entre cluster_cah et classes_indice
croisement <- table(cluster_cah,classes_indice)
# Transformer le tableau en format long
table_long <- as.data.frame(croisement)
# Affichage avec ggplot2
ggplot(table_long, aes(cluster_cah, classes_indice, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), color = "black") +
scale_fill_gradient(low = "lightblue", high = "blue") +
labs(title = "Croisement entre la variable cluster le la CAH et les classes d'indice", x = "cluster_cah", y = "classes_indice") +
theme_minimal() + theme(axis.text.x = element_text(angle = 30, hjust = 1))  # Incliner les labels à 45°
# Taux de bien classés
print(sum(diag(croisement)) * 100 / sum(croisement))
# Le taux de bien classé pour la classification hiérarchique sur composantes principales est de 77,5%. Ainsi, le taux d'erreur (TEC) vaut 22,5%.
# Équation de LD1
training$LD1 <- (-0.8011271 * training$Croi_PIB_hab) +
(-1.0221042 * training$Ctr_agri_PIB) +
(-0.7387970 * training$Poids_Exp_sur_PIB) +
(-1.98717547 * training$Ctr_Tertiaire_PIB) +
-0.9964991 * training$Tx_Eau_potable +
(-1.77999388 * training$Ctrind_PIB) +
(-0.09259953 * training$Taux_pene_Tel_mob) +
(-1.2128112 * training$`Part_Pop_0-14 ans`) +
(-1.4673745 * training$Part_Pop_65ans_et_plus) +
(-1.4073714 * training$Pop_rurale) +
-0.6787517 * training$Crois_pop +
(-1.6746530 * training$Use_Index_Internet)
# Équation de LD2
training$LD2 <-  0.81166331 * training$Croi_PIB_hab +
(-2.31120389 * training$Ctr_agri_PIB) +
(0.07567048 * training$Poids_Exp_sur_PIB) +
(-2.34130823 * training$Ctr_Tertiaire_PIB) +
1.81789260 * training$Tx_Eau_potable +
(-0.67709946 * training$Ctrind_PIB) +
(-0.31712505 * training$Taux_pene_Tel_mob) +
(0.92156238 * training$`Part_Pop_0-14 ans`) +
(-0.12566144 * training$Part_Pop_65ans_et_plus) +
0.95754218 * training$Pop_rurale +
(0.33896056 * training$Crois_pop) +
(-0.02372936 * training$Use_Index_Internet)
ggplot(training, aes(x = LD1, y = LD2, color = classe_indice)) +
geom_point(size=1) +
stat_ellipse(geom = "path", alpha = 0.8) +
labs(title = "Nuage des individus", x = "Premier axe discriminant : 93,22%", y = "Second axe discriminant : 5,23%")
ggplot(training, aes(x = LD1, fill = classe_indice)) +
geom_histogram(binwidth = 1, position = "dodge") +
labs(title = "Histogramme suivant la première variable discriminante", x = "Valeurs", y = "Fréquence") +
scale_fill_manual(values = c("red", "blue", "green","yellow"))
ggplot(training, aes(x = LD1, color = classe_indice, fill = classe_indice)) +
geom_density(alpha = 0.5) +
labs(title = "Discrimination suivant la première variable", x = "Valeurs", y = "Densité") +
scale_color_manual(values = c("red", "blue", "green","yellow")) +
scale_fill_manual(values = c("red", "blue", "green","yellow"))
ggplot(training, aes(x = LD2, fill = classe_indice)) +
geom_histogram(binwidth = 1, position = "dodge") +
labs(title = "Histogramme suivant la deuxième variable discriminante", x = "Valeurs", y = "Fréquence") +
scale_fill_manual(values = c("red", "blue", "green","yellow"))
ggplot(training, aes(x = LD2, color = classe_indice, fill = classe_indice)) +
geom_density(alpha = 0.5) +
labs(title = "Discrimination suivant la deuxième variable", x = "Valeurs", y = "Densité") +
scale_color_manual(values = c("red", "blue", "green","yellow")) +
scale_fill_manual(values = c("red", "blue", "green","yellow"))
predicted <- predict(data_lda, testing)
names(predicted)
score <- predicted$x
classement <- data.frame(predicted$class)
affectation <- cbind(testing, score, classement)
vect <- predict(data_lda, testing)$class
quality <- table(Actual = testing$classe_indice, Predicted = vect)
quality
# Pourcentage de bien classés
sum(diag(quality))/sum(quality)*100
# Le pourcentage de bien classés est de 95,2%. Par conséquant, le taux d'erreur de classement ici est de 4,8%.
library(ggplot2)
# Convertir la table de confusion en format long pour ggplot
quality_df <- as.data.frame(as.table(quality))
# Visualiser la matrice de confusion avec ggplot
ggplot(quality_df, aes(Actual, Predicted, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), color = "red", size = 5) +
scale_fill_gradient(low = "pink", high = "blue") +
theme_minimal() +
labs(title="Matrice de confusion de l'AFD", x = "Classe réelle", y = "Classe prédite", fill = "Fréquence") +
theme(axis.text.x = element_text(angle = 20, hjust = 1))
# Pourcentage de bien classés
sum(diag(quality))/sum(quality)*100
# Le pourcentage de bien classés est de 95,2%. Par conséquant, le taux d'erreur de classement ici est de 4,8%.
data_kmeans <- data
# Calcul de la somme des carrés intra-cluster (WSS) pour différents k
wss <- sapply(1:10,function(k) { kmeans(data, centers = k, nstart = 25)$tot.withinss })
plot(1:10, wss, type = "b", pch = 19, frame = FALSE, xlab = "Nombre de
clusters k", ylab = "Somme des carrés intra-cluster", main = "Méthode du
coude (Elbow Method)")
library(cluster)
# Nombre de clusters à tester
k_values <- 2:10  # Par exemple, tester k allant de 2 à 10
# Liste pour stocker les résultats de silhouette
sil_scores <- vector("list", length = length(k_values))
# Calculer la silhouette pour chaque k
for (k in k_values) {
# Effectuer le clustering k-means
kmeans_result <- kmeans(data, centers = k, nstart = 25)
# Calculer la silhouette pour les résultats de clustering
sil_scores[[k - 1]] <- silhouette(kmeans_result$cluster, dist(data_norm))
}
# Calculer la moyenne des silhouettes pour chaque k
avg_silhouette <- sapply(sil_scores, function(sil) mean(sil[, 3]))
# Tracer la courbe de silhouette moyenne en fonction de k
plot(k_values, avg_silhouette, type = "b", pch = 19, col = "blue",
xlab = "Nombre de clusters (k)", ylab = "Silhouette moyenne",
main = "Courbe de silhouette en fonction du nombre de clusters")
set.seed(7)
data_kmeans <- data_indice %>% select(-clust)
data_kmeans <- data_kmeans%>%column_to_rownames(var="Pays")
# Effectuer le clustering k-means avec 4 classes
kmeans_result <- kmeans(data_kmeans$indice, centers = 4, nstart = 25)
data_kmeans$cluster <- as.factor(kmeans_result$cluster)
#head(data_kmeans,120)
print(data_kmeans[1:120,c("cluster","indice")])
# Renommer la variable `cluster`
data_kmeans$cluster <- as.factor(data_kmeans$cluster)
data_kmeans <- rename(data_kmeans, classe_indice = cluster)
PCA_indice <- PCA(data_kmeans, ncp=5, quanti.sup = "indice", quali.sup = "classe_indice", graph = TRUE)
# Visualisation avec ellipses et coloration par variable quantitative supplémentaire
fviz_pca_biplot(PCA_indice, axes=c(1,2),
habillage = "classe_indice", # Coloration par la variable qualitative (ellipses)
addEllipses = TRUE, # Ajouter des ellipses de concentration
col.var = "red", # Couleur des variables
col.ind = "blue", # Coloration des individus
repel = TRUE) +
theme_minimal()
# Visualisation sur les axes 1 et 3
fviz_pca_biplot(PCA_indice, axes=c(1,3),
habillage = "classe_indice",
addEllipses = TRUE,
col.var = "red",
col.ind = "blue",
repel = TRUE) +
theme_minimal()
data_kmeans$classe_indice <- factor(data_kmeans$classe_indice, levels = c(1,2,3,4), labels = c("Pays développés et avancés","Pays à économie agricole et faible développement","Pays en développement et à économie tertiaire","Pays émergents et en transition économique"))
# Indice moyen dans chaque groupe
indices_moyens <- data_kmeans %>%group_by(classe_indice) %>%summarize(across(indice, mean, na.rm = TRUE))
indices_moyens
# Distribution des indices dans chaque classe
ggplot(data = data_kmeans, aes(x=classe_indice, y=indice)) +
geom_line(color = "red") +
geom_point(color = "blue", size = 2) +
labs(title = "Distribution des indices normalisés",
x = "classe indice",
y = "Indice") +
theme_minimal() + theme(axis.text.x = element_text(angle = 30, hjust = 1))
# Autres visualisations
# Préparation des données
new_df <- data.frame(
Indice = data_kmeans$indice,
Classe = factor(data_kmeans$classe_indice)
) %>%
arrange(Indice)
# Calcul des moyennes par classe
class_means <- new_df %>%
group_by(Classe) %>%
summarise(mean_val = mean(Indice))
# Création du graphique
ggplot(new_df, aes(x = Indice, fill = Classe)) +
# Histogramme semi-transparent
geom_histogram(aes(y = after_stat(density)),
alpha = 0.5,
position = "identity",
bins = 30) +
# Courbe de densité
geom_density(aes(color = Classe),
alpha = 0,
linewidth = 1) +
# Points sur l'axe x pour montrer la distribution
geom_rug(aes(color = Classe),
alpha = 0.6,
linewidth = 0.5) +
# Lignes verticales pour les moyennes
geom_vline(data = class_means,
aes(xintercept = mean_val, color = Classe),
linetype = "dashed",
linewidth = 0.8) +
# Personnalisation du thème
theme_minimal() +
theme(
legend.position = "top",
panel.grid.minor = element_blank(),
plot.title = element_text(face = "bold"),
plot.subtitle = element_text(color = "grey40")
) +
# Labels
labs(
title = "Distribution des classes par densité",
subtitle = "Chevauchement de l'indice entre classes",
x = "Valeur de l'indice",
y = "Densité",
fill = "Classe",
color = "Classe"
) +
# Échelle de couleurs personnalisée
scale_fill_brewer(palette = "Set2") +
scale_color_brewer(palette = "Set2") +
# Facettes par classe
facet_wrap(~Classe, nrow = 3, scales = "free_y") +
# Ajustement des marges
theme(
strip.background = element_rect(fill = "grey95"),
strip.text = element_text(color = "black", face = "bold")
)
intervalle_indice <- data_kmeans %>%
group_by(classe_indice) %>%
summarize(min_indice = min(indice, na.rm = TRUE),
max_indice = max(indice, na.rm = TRUE))
intervalle_indice
# Copie du dataframe initial, standardisé
data_AFD <- as.data.frame(scale(df))
# Ajout de la colonne classe_indice
data_AFD$classe_indice <- as.factor(data_kmeans$classe_indice)
data_AFD <- rename(data_AFD,
Croi_PIB_hab = "Croi PIB/hab",
Ctr_agri_PIB = "Ctr_agri_PIB(%)",
Poids_Exp_sur_PIB = "Poids_Exp_sur_PIB(%)",
Ctr_Tertiaire_PIB = "Ctr_Tertiaire_PIB(%)",
Ctrind_PIB = "Ctrind_PIB(%)")
head(data_AFD)
# Choix de l'échantilllon test
set.seed(0)
samples <- sample(2, nrow(data_AFD),
replace = TRUE,
prob = c(0.8, 0.2))
training <- data_AFD[samples==1,]
testing <- data_AFD[samples==2,]
# L'analyse discriminante
data_lda <- lda(classe_indice~., training)
data_lda
# Probabilités à priori du groupe
data_lda[["prior"]]
# Moyenne des groupes
data_lda[["means"]]
# Coefficients des discriminants linéaires
data_lda[["scaling"]]
# Équation de LD1
training$LD1 <- (-0.8011271 * training$Croi_PIB_hab) +
(-1.0221042 * training$Ctr_agri_PIB) +
(-0.7387970 * training$Poids_Exp_sur_PIB) +
(-1.98717547 * training$Ctr_Tertiaire_PIB) +
-0.9964991 * training$Tx_Eau_potable +
(-1.77999388 * training$Ctrind_PIB) +
(-0.09259953 * training$Taux_pene_Tel_mob) +
(-1.2128112 * training$`Part_Pop_0-14 ans`) +
(-1.4673745 * training$Part_Pop_65ans_et_plus) +
(-1.4073714 * training$Pop_rurale) +
-0.6787517 * training$Crois_pop +
(-1.6746530 * training$Use_Index_Internet)
# Équation de LD2
training$LD2 <-  0.81166331 * training$Croi_PIB_hab +
(-2.31120389 * training$Ctr_agri_PIB) +
(0.07567048 * training$Poids_Exp_sur_PIB) +
(-2.34130823 * training$Ctr_Tertiaire_PIB) +
1.81789260 * training$Tx_Eau_potable +
(-0.67709946 * training$Ctrind_PIB) +
(-0.31712505 * training$Taux_pene_Tel_mob) +
(0.92156238 * training$`Part_Pop_0-14 ans`) +
(-0.12566144 * training$Part_Pop_65ans_et_plus) +
0.95754218 * training$Pop_rurale +
(0.33896056 * training$Crois_pop) +
(-0.02372936 * training$Use_Index_Internet)
ggplot(training, aes(x = LD1, y = LD2, color = classe_indice)) +
geom_point(size=1) +
stat_ellipse(geom = "path", alpha = 0.8) +
labs(title = "Nuage des individus", x = "Premier axe discriminant : 93,22%", y = "Second axe discriminant : 5,23%")
ggplot(training, aes(x = LD1, fill = classe_indice)) +
geom_histogram(binwidth = 1, position = "dodge") +
labs(title = "Histogramme suivant la première variable discriminante", x = "Valeurs", y = "Fréquence") +
scale_fill_manual(values = c("red", "blue", "green","yellow"))
ggplot(training, aes(x = LD1, color = classe_indice, fill = classe_indice)) +
geom_density(alpha = 0.5) +
labs(title = "Discrimination suivant la première variable", x = "Valeurs", y = "Densité") +
scale_color_manual(values = c("red", "blue", "green","yellow")) +
scale_fill_manual(values = c("red", "blue", "green","yellow"))
ggplot(training, aes(x = LD2, fill = classe_indice)) +
geom_histogram(binwidth = 1, position = "dodge") +
labs(title = "Histogramme suivant la deuxième variable discriminante", x = "Valeurs", y = "Fréquence") +
scale_fill_manual(values = c("red", "blue", "green","yellow"))
ggplot(training, aes(x = LD2, color = classe_indice, fill = classe_indice)) +
geom_density(alpha = 0.5) +
labs(title = "Discrimination suivant la deuxième variable", x = "Valeurs", y = "Densité") +
scale_color_manual(values = c("red", "blue", "green","yellow")) +
scale_fill_manual(values = c("red", "blue", "green","yellow"))
predicted <- predict(data_lda, testing)
names(predicted)
score <- predicted$x
classement <- data.frame(predicted$class)
affectation <- cbind(testing, score, classement)
vect <- predict(data_lda, testing)$class
quality <- table(Actual = testing$classe_indice, Predicted = vect)
quality
# Pourcentage de bien classés
sum(diag(quality))/sum(quality)*100
# Le pourcentage de bien classés est de 76,2%. Par conséquant, le taux d'erreur de classement ici est de 23,8%.
quality
# Pour des besoins d'affichage de la matrice de confusion, nous allons réduire les noms.
colnames(quality) <- c("Pays développés","Pays agricoles","Pays en développement","Pays émergents")
rownames(quality) <- c("Pays développés","Pays agricoles","Pays en développement","Pays émergents")
quality
library(ggplot2)
# Convertir la table de confusion en format long pour ggplot
quality_df <- as.data.frame(as.table(quality))
# Visualiser la matrice de confusion avec ggplot
ggplot(quality_df, aes(Actual, Predicted, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), color = "red", size = 5) +
scale_fill_gradient(low = "pink", high = "blue") +
theme_minimal() +
labs(title="Matrice de confusion de l'AFD", x = "Classe réelle", y = "Classe prédite", fill = "Fréquence") +
theme(axis.text.x = element_text(angle = 0, hjust = 1))
# Pourcentage de bien classés
sum(diag(quality))/sum(quality)*100
# Le pourcentage de bien classés est de 95,2%. Par conséquant, le taux d'erreur de classement ici est de 4,8%.
library(ggplot2)
# Convertir la table de confusion en format long pour ggplot
quality_df <- as.data.frame(as.table(quality))
# Visualiser la matrice de confusion avec ggplot
ggplot(quality_df, aes(Actual, Predicted, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), color = "red", size = 5) +
scale_fill_gradient(low = "pink", high = "blue") +
theme_minimal() +
labs(title="Matrice de confusion de l'AFD", x = "Classe réelle", y = "Classe prédite", fill = "Fréquence") +
theme(axis.text.x = element_text(angle = 10, hjust = 1))
# Pourcentage de bien classés
sum(diag(quality))/sum(quality)*100
# Le pourcentage de bien classés est de 95,2%. Par conséquant, le taux d'erreur de classement ici est de 4,8%.
library(ggplot2)
# Convertir la table de confusion en format long pour ggplot
quality_df <- as.data.frame(as.table(quality))
# Visualiser la matrice de confusion avec ggplot
ggplot(quality_df, aes(Actual, Predicted, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), color = "red", size = 5) +
scale_fill_gradient(low = "pink", high = "blue") +
theme_minimal() +
labs(title="Matrice de confusion de l'AFD", x = "Classe réelle", y = "Classe prédite", fill = "Fréquence") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Pourcentage de bien classés
sum(diag(quality))/sum(quality)*100
# Le pourcentage de bien classés est de 95,2%. Par conséquant, le taux d'erreur de classement ici est de 4,8%.
library(ggplot2)
# Convertir la table de confusion en format long pour ggplot
quality_df <- as.data.frame(as.table(quality))
# Visualiser la matrice de confusion avec ggplot
ggplot(quality_df, aes(Actual, Predicted, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), color = "red", size = 5) +
scale_fill_gradient(low = "pink", high = "blue") +
theme_minimal() +
labs(title="Matrice de confusion de l'AFD", x = "Classe réelle", y = "Classe prédite", fill = "Fréquence") +
theme(axis.text.x = element_text(angle = 20, hjust = 1))
# Pourcentage de bien classés
sum(diag(quality))/sum(quality)*100
# Le pourcentage de bien classés est de 95,2%. Par conséquant, le taux d'erreur de classement ici est de 4,8%.
unique(data_cluster$clust)
unique(data_AFD$classe_indice)
# Récupérer les clusters de la CAH
cluster_cah <- data_cluster$clust
# Renommer les classes pour des besoins d'affichage de la matrice
cluster_cah <- factor(cluster_cah, levels = c("Pays en développement et à économie tertiaire","Pays à économie agricole et faible développement","Pays émergents et en transition économique","Pays développés et avancés"), labels = c("Pays en développement", "Pays agricoles","Pays émergents", "Pays développés"))
# Récupérer les classes d'indice
classes_indice <- data_AFD$classe_indice
classe_indice <- factor(classe_indice, levels = c("Pays à économie agricole et faible développement", "Pays en développement et à économie tertiaire", "Pays émergents et en transition économique", "Pays développés et avancés"), labels = c("Pays agricoles", "Pays en développement","Pays émergents", "Pays développés") )
# Récupérer les clusters de la CAH
cluster_cah <- data_cluster$clust
# Renommer les classes pour des besoins d'affichage de la matrice
cluster_cah <- factor(cluster_cah, levels = c("Pays en développement et à économie tertiaire","Pays à économie agricole et faible développement","Pays émergents et en transition économique","Pays développés et avancés"), labels = c("Pays en développement", "Pays agricoles","Pays émergents", "Pays développés"))
# Récupérer les classes d'indice
classes_indice <- data_AFD$classe_indice
classes_indice <- factor(classes_indice, levels = c("Pays à économie agricole et faible développement", "Pays en développement et à économie tertiaire", "Pays émergents et en transition économique", "Pays développés et avancés"), labels = c("Pays agricoles", "Pays en développement","Pays émergents", "Pays développés") )
# Réorganiser les niveaux de manière cohérente
levels_order <- c("Pays agricoles", "Pays en développement","Pays émergents", "Pays développés")
# Ajuster les niveaux pour cluster_cah et classes_indice
cluster_cah <- factor(cluster_cah, levels = levels_order)
classes_indice <- factor(classes_indice, levels = levels_order)
# Croisement entre cluster_cah et classes_indice
croisement <- table(cluster_cah,classes_indice)
# Transformer le tableau en format long
table_long <- as.data.frame(croisement)
# Affichage avec ggplot2
ggplot(table_long, aes(cluster_cah, classes_indice, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), color = "black") +
scale_fill_gradient(low = "lightblue", high = "blue") +
labs(title = "Croisement entre la variable cluster le la CAH et les classes d'indice", x = "cluster_cah", y = "classes_indice") +
theme_minimal() + theme(axis.text.x = element_text(angle = 30, hjust = 1))  # Incliner les labels à 45°
# Taux de bien classés
print(sum(diag(croisement)) * 100 / sum(croisement))
# Le taux de bien classé pour la classification hiérarchique sur composantes principales est de 77,5%. Ainsi, le taux d'erreur (TEC) vaut 22,5%.
